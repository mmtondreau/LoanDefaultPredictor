{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AmxzndBnaY28"
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "\n",
    "# Data packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "# Visualization Packages\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MkEkBhXYaY29"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "\n",
    "class Block(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_units, dropout=0.2, activation=F.relu):\n",
    "        super(Block, self).__init__()\n",
    "        self.layer = nn.Linear(input_size, hidden_units)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        # self.batchNorm = nn.BatchNorm1d(hidden_units)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        # x = self.batchNorm(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LDPModel(pl.LightningModule):\n",
    "    def __init__(self, num_features, num_classes, hidden_units):\n",
    "        super(LDPModel, self).__init__()\n",
    "        self.example_input_array = torch.Tensor(32, num_features)\n",
    "        all_layers = []\n",
    "        for hidden_unit in hidden_units:\n",
    "            all_layers.append(Block(input_size=num_features, hidden_units=hidden_unit))\n",
    "            num_features = hidden_unit\n",
    "        all_layers.append(nn.Linear(hidden_units[-1], num_classes))\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return F.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7nmPrMjQaY3C"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import Accuracy, MeanMetric, AUROC\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_loan_default.ldp_model import LDPModel\n",
    "\n",
    "\n",
    "class LDPLitModule(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        num_features,\n",
    "        pytorch_model=None,\n",
    "        num_classes=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.example_input_array = torch.Tensor(32, num_features)\n",
    "        self.hidden_units = config[\"hidden_units\"]\n",
    "        self.learning_rate = config[\"learning_rate\"]\n",
    "        if pytorch_model is not None:\n",
    "            self.model = pytorch_model\n",
    "        else:\n",
    "            self.model = LDPModel(\n",
    "                num_features=num_features,\n",
    "                num_classes=num_classes,\n",
    "                hidden_units=self.hidden_units,\n",
    "            )\n",
    "\n",
    "        self.auroc = AUROC(task=\"binary\")\n",
    "\n",
    "        self.val_loss = []\n",
    "        self.val_auroc = []\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, auroc = self._shared_eval(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_auroc\", auroc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.val_loss.clear()\n",
    "        self.val_auroc.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        loss, auroc = self._shared_eval(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_auroc\", auroc, prog_bar=True)\n",
    "        self.val_auroc.append(auroc)\n",
    "        self.val_loss.append(loss)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_loss = torch.stack(self.val_loss).mean()\n",
    "        avg_auroc = torch.stack(self.val_auroc).mean()\n",
    "        self.log(\"ptl/val_loss\", avg_loss, sync_dist=True)\n",
    "        self.log(\"ptl/val_auroc\", avg_auroc, sync_dist=True, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        loss, auroc = self._shared_eval(batch, batch_idx)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_auroc\", auroc)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            self.parameters(), lr=self.learning_rate, weight_decay=0.001\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer=optimizer, patience=5, factor=0.1, mode=\"min\"\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"train_loss\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def _shared_eval(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        predictions = self(x)\n",
    "        loss = F.binary_cross_entropy(predictions, y)\n",
    "        auroc = self.auroc(predictions, y)\n",
    "        return loss, auroc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3s__DqK0aY3A"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class LDPDataModule(pl.LightningDataModule):\n",
    "    # REMOVE_FEATURES = [\"Default\", \"LoanID\"]\n",
    "    REMOVE_FEATURES = [\n",
    "        \"CreditScore\",\n",
    "        \"CreditUtilizationRate\",\n",
    "        \"Default\",\n",
    "        \"LoanID\",\n",
    "        \"HasCoSigner\",\n",
    "        \"LoanPurpose\",\n",
    "        \"HasDependents\",\n",
    "        \"HasMortgage\",\n",
    "        \"MaritalStatus\",\n",
    "        \"EmploymentType\",\n",
    "        \"Education\",\n",
    "        \"LoanTerm\",\n",
    "        \"NumCreditLines\",\n",
    "    ]\n",
    "    TEXT_COLUMNS = [\"LoanPurpose\", \"MaritalStatus\"]\n",
    "    YES_NO_COLUMNS = [\"HasMortgage\", \"HasDependents\", \"HasCoSigner\"]\n",
    "\n",
    "    def __init__(self, data_dir: str = \"./\", batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.setup_complete = False\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        response = requests.get(\n",
    "            \"https://raw.githubusercontent.com/mmtondreau/LoanDefaultPredictor/main/train.csv\"\n",
    "        )\n",
    "        with open(os.path.join(self.data_dir, \"train.csv\"), \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        if self.setup_complete == False:\n",
    "            self.setup_complete = True \n",
    "            data_df = pd.read_csv(os.path.join(self.data_dir, \"train.csv\"))\n",
    "            self.df = data_df\n",
    "            self.df[\"ID\"] = self.df.index\n",
    "            self.feature_engineer(data_df)\n",
    "            y_data = data_df[\"Default\"].to_numpy()\n",
    "            z_data = data_df[\"ID\"].to_numpy()\n",
    "            x_data_transformed = self.transform_data(data_df)\n",
    "            self.width = x_data_transformed.shape[1]\n",
    "\n",
    "            dataset_size = len(x_data_transformed)\n",
    "            train_size = int(0.8 * dataset_size)\n",
    "            val_size = int(0.1 * dataset_size)\n",
    "            test_size = dataset_size - train_size - val_size\n",
    "\n",
    "            dataset = TensorDataset(\n",
    "                torch.tensor(x_data_transformed.to_numpy(), dtype=torch.float32),\n",
    "                torch.tensor(y_data, dtype=torch.float32).view(-1, 1),\n",
    "                torch.tensor(z_data, dtype=torch.int32),\n",
    "            )\n",
    "\n",
    "            self.train_dataset, self.val_dataset, self.test_dataset = random_split(\n",
    "                dataset, (train_size, val_size, test_size)\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def feature_engineer(self, df):\n",
    "        df[\"MonthlyIncome\"] = round(df[\"Income\"] / 12.0, 2)\n",
    "        df[\"InterestRate\"] = df[\"InterestRate\"] / 100.0\n",
    "        df[\"MonthlyPayment\"] = round(\n",
    "            (\n",
    "                (df[\"LoanAmount\"] * df[\"InterestRate\"] / 12.0)\n",
    "                * ((1 + df[\"InterestRate\"] / 12.0) ** df[\"LoanTerm\"])\n",
    "            )\n",
    "            / (((1 + df[\"InterestRate\"] / 12.0) ** df[\"LoanTerm\"]) - 1),\n",
    "            0,\n",
    "        )\n",
    "        df[\"NewDTI\"] = round(\n",
    "            df[\"DTIRatio\"] + (df[\"MonthlyPayment\"] / df[\"MonthlyIncome\"]), 2\n",
    "        )\n",
    "        df[\"LoanToIncome\"] = round(df[\"LoanAmount\"] / df[\"Income\"], 2)\n",
    "        df[\"MonthlyPaymentToIncome\"] = round(df[\"MonthlyPayment\"] / df[\"Income\"], 4)\n",
    "\n",
    "    def one_hot(self, df, columns):\n",
    "        if len(columns) == 0:\n",
    "            return df\n",
    "        for col in columns:\n",
    "            print(col)\n",
    "            categories = df[col].unique()\n",
    "            category_to_index = {\n",
    "                category: index for index, category in enumerate(categories)\n",
    "            }\n",
    "            df.loc[:, col] = df[col].map(category_to_index)\n",
    "            num_categories = len(categories)\n",
    "            one_hot_encoding = torch.nn.functional.one_hot(\n",
    "                torch.tensor(df[col]), num_classes=num_categories\n",
    "            )\n",
    "            one_hot_df = pd.DataFrame(one_hot_encoding.numpy(), columns=categories)\n",
    "            df = pd.concat([df, one_hot_df], axis=1)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def transform_education(self, df):\n",
    "        if \"Education\" in self.REMOVE_FEATURES:\n",
    "            return\n",
    "        education_mapping = {\"High School\": 0, \"Bachelor's\": 1, \"Master's\": 2, \"PhD\": 3}\n",
    "\n",
    "        df[\"Education\"] = df[\"Education\"].replace(education_mapping)\n",
    "\n",
    "    def transform_empoloyment(self, df):\n",
    "        if \"EmploymentType\" in self.REMOVE_FEATURES:\n",
    "            return\n",
    "        mapping = {\n",
    "            \"Unemployed\": 0,\n",
    "            \"Part-time\": 1,\n",
    "            \"Self-employed\": 2,\n",
    "            \"Full-time\": 3,\n",
    "        }\n",
    "        df[\"EmploymentType\"] = df[\"EmploymentType\"].replace(mapping)\n",
    "\n",
    "    def transform_data(self, df):\n",
    "        train_df_tmp = df.loc[:, ~df.columns.isin(self.REMOVE_FEATURES)]\n",
    "        train_df_tmp = self.one_hot(\n",
    "            train_df_tmp, set(self.TEXT_COLUMNS) - set(self.REMOVE_FEATURES)\n",
    "        )\n",
    "        self.transform_education(train_df_tmp)\n",
    "        self.transform_empoloyment(train_df_tmp)\n",
    "\n",
    "        for yes_no_column in set(self.YES_NO_COLUMNS) - set(self.REMOVE_FEATURES):\n",
    "            train_df_tmp[yes_no_column] = df[yes_no_column].replace({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "        normalized_data = self.normalize(train_df_tmp)\n",
    "        return normalized_data\n",
    "\n",
    "    def normalize(self, x):\n",
    "        x_mean = np.mean(x, axis=0)\n",
    "        x_std = np.std(x, axis=0)\n",
    "\n",
    "        # Normalize each feature independently\n",
    "        return (x - x_mean) / x_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0341, -0.5340,  0.0670,  1.2833,  0.3672, -1.2135, -1.6108, -0.5340,\n",
      "         0.1746, -0.1196, -0.0172,  0.0700])\n",
      "tensor([0.])\n",
      "          LoanID  Age  Income  LoanAmount  CreditScore  MonthsEmployed  NumCreditLines  InterestRate  LoanTerm  DTIRatio   Education EmploymentType MaritalStatus HasMortgage HasDependents LoanPurpose HasCoSigner  Default    ID  MonthlyIncome  MonthlyPayment  NewDTI  LoanToIncome  MonthlyPaymentToIncome\n",
      "8940  XAP1XVO34R   59   61694      132326          677             104               4        0.1593        24      0.22  Bachelor's     Unemployed        Single         Yes            No       Other         Yes        0  8940        5141.17          6475.0    1.48          2.14                   0.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type        | Params | In sizes | Out sizes\n",
      "-------------------------------------------------------------\n",
      "0 | model | LDPModel    | 2.1 K  | [32, 12] | [32, 1]  \n",
      "1 | auroc | BinaryAUROC | 0      | ?        | ?        \n",
      "-------------------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977be9e647e5488fa73b4e6e87d467b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078a80439f794ef28ba8255f8ea4c884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bc32c6c8694d748b1d2f8dde7af4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5466b9581f1f41d995a43027201304ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6760caca28f1435fbc99a8084e677c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c749f63554b4701aaf9485842122dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3829340584914bb5bf1cea83b2348c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a95218b8ef44f7802ce48c27ae1969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae39298c19d1440fa475f77b8cfc47ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15298249aa0e40d5a5553d9f547468f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e252d11388840ef96944aa4c0fc51bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2281411d5ac9431a9479a753e029b2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch_loan_default.ldp_data_module import LDPDataModule\n",
    "from torch_loan_default.ldp_lit_module import LDPLitModule\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch_loan_default.simple_data_module import EvenOddDataModule\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"hidden_units\": [48, 24, 12],\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 1280,\n",
    "}\n",
    "\n",
    "dm = LDPDataModule(batch_size=config[\"batch_size\"])\n",
    "dm.prepare_data()\n",
    "dm.setup(stage=\"fit\")\n",
    "\n",
    "x, y, z = next(iter(dm.train_dataloader()))\n",
    "print(x[0])\n",
    "print(y[0])\n",
    "\n",
    "df = dm.df\n",
    "\n",
    "print(df[df[\"ID\"] == z[0].item()].to_string())\n",
    "\n",
    "model = LDPLitModule(config, num_features=dm.width)\n",
    "trainer = pl.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    max_epochs=100,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor=\"ptl/val_loss\", mode=\"min\", patience=5, min_delta=0.0001\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            monitor=\"ptl/val_auroc\", mode=\"max\", filename=\"{epoch}-{val_auroc:.2f}\"\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "trainer.fit(model, datamodule=dm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fec128b590140999761c685e99a10c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_auroc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7405419945716858     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3179919123649597     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_auroc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7405419945716858    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3179919123649597    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7673, -0.5231,  0.9716,  ...,  0.0758,  0.4510, -0.1525],\n",
      "        [-0.6336,  1.6030, -1.6077,  ..., -0.5239, -0.9583, -0.7196],\n",
      "        [-0.4335, -1.5474, -0.7437,  ...,  0.0623,  0.5474, -0.0208],\n",
      "        ...,\n",
      "        [ 0.3003, -1.0797,  0.2655,  ...,  0.5138,  0.6622,  0.5790],\n",
      "        [ 0.2336, -1.3298, -1.3094,  ..., -0.5576, -0.4809, -0.4602],\n",
      "        [ 0.0335,  0.0680, -1.4576,  ..., -0.5239, -0.8665, -0.5797]])\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([0.0847, 0.1316, 0.2257,  ..., 0.0596, 0.0694, 0.0701],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.test(model, datamodule=dm)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "x, y, _ = next(iter(dm.test_dataloader()))\n",
    "y_hat = model(x)\n",
    "print(x)\n",
    "print(torch.flatten(y))\n",
    "print(torch.flatten(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
